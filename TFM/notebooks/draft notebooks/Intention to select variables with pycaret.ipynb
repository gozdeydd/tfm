{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b56777a",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pycaret.classification import *\n",
    "import os\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, confusion_matrix, classification_report,average_precision_score, precision_recall_curve\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import geopandas as gpd\n",
    "import sweetviz as sv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3ff3a4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading dataset\n",
    "data = pd.read_pickle('../data/manipulated/geo_city.pkl')\n",
    "# to have a non spatial modeling we drop spatial features keeping longitude and latitude for the buildings    \n",
    "data.head()\n",
    "data.drop(columns=['geometry'], axis=1, inplace=True)\n",
    "\n",
    "#turning to pandas dataframe\n",
    "data = pd.DataFrame(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a82ed346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modified column names:\n",
      "Index(['obj_type', 'name', 'info', 'damage_gra', 'det_method', 'notation',\n",
      "       'or_src_id', 'dmg_src_id', 'cd_value', 'real', 'province', 'city',\n",
      "       'population', 'income', 'total_sales', 'second_sales', 'water_access',\n",
      "       'elec_cons', 'building_perm', 'land_permited', 'labour_fource',\n",
      "       'unemployment', 'agricultural', 'life_time', 'hb_per100000',\n",
      "       'fertility', 'hh_size', 'point'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#pycaret recognize some columns as duplicate. in order we decide which ones could be, we check all the columns\n",
    "def make_columns_distinct(df):\n",
    "    \"\"\"A function that makes all column names distinct.\"\"\"\n",
    "    modified_columns = []\n",
    "    seen_columns = set()\n",
    "\n",
    "    for column in df.columns:\n",
    "        modified_column = column\n",
    "        counter = 1\n",
    "\n",
    "        while modified_column in seen_columns:\n",
    "            modified_column = f\"{column}_{counter}\"\n",
    "            counter += 1\n",
    "\n",
    "        modified_columns.append(modified_column)\n",
    "        seen_columns.add(modified_column)\n",
    "\n",
    "    df.columns = modified_columns\n",
    "    return df\n",
    "\n",
    "\n",
    "# Make the columns distinct\n",
    "df_distinct = make_columns_distinct(data)\n",
    "\n",
    "# Print the modified column names\n",
    "print(\"Modified column names:\")\n",
    "print(df_distinct.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3eb8dafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns with geometry\n",
    "#df_distinct.drop(columns=['Geometry','centroid'], axis=1, inplace=True)                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0a94c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5be9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a quick EDA with sweetviz\n",
    "#anaylsis = sv.analyze(df_distinct)\n",
    "#anaylsis.show_html('df_distinct.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ae9c401b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "obj_type\n",
      "name\n",
      "info\n",
      "damage_gra\n",
      "det_method\n",
      "notation\n",
      "or_src_id\n",
      "dmg_src_id\n",
      "cd_value\n",
      "real\n",
      "province\n",
      "city\n",
      "population\n",
      "income\n",
      "total_sales\n",
      "second_sales\n",
      "water_access\n",
      "elec_cons\n",
      "building_perm\n",
      "land_permited\n",
      "labour_fource\n",
      "unemployment\n",
      "agricultural\n",
      "life_time\n",
      "hb_per100000\n",
      "fertility\n",
      "hh_size\n",
      "point\n"
     ]
    }
   ],
   "source": [
    "def clean_data(data):\n",
    "    \"\"\"A  function that cleans the data.\"\"\"\n",
    "    data = data.dropna()\n",
    "    data = data.drop_duplicates()\n",
    "    return data\n",
    "\n",
    "\n",
    "def remove_duplicate_columns(data):\n",
    "    \"\"\" A function that removes duplicate columns from a DataFrame or a 2D list.\"\"\"\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # Remove duplicate columns from a DataFrame\n",
    "        return data.loc[:, ~data.columns.duplicated()]\n",
    "    elif isinstance(data, list) and all(isinstance(row, list) for row in data):\n",
    "        # Remove duplicate columns from a 2D list\n",
    "        transposed = list(map(list, zip(*data)))  # Transpose the list\n",
    "        deduplicated = [list(t) for t in set(tuple(row) for row in transposed)]  # Deduplicate\n",
    "        return list(map(list, zip(*deduplicated)))  # Transpose back\n",
    "    else:\n",
    "        raise ValueError(\"Input must be a DataFrame or a 2D list\")\n",
    "\n",
    "clean_data(df_distinct)\n",
    "remove_duplicate_columns(df_distinct)\n",
    "pd.set_option('display.max_columns', None)\n",
    "column_names = data.columns.tolist()\n",
    "\n",
    "\n",
    "for column in df_distinct.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "68c05313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ordinalization of target vaiable so that pycaret can use it for its models\n",
    "\n",
    "mapping = {\n",
    "    \"Damaged\": 3,\n",
    "    \"Destroyed\": 4,\n",
    "    \"No visible damage\": 1,\n",
    "    \"Possibly damaged\": 2\n",
    "}\n",
    "\n",
    "df_distinct['damage_gra'] = df_distinct['damage_gra'].replace(mapping)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bad4b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing some columns as ve observe as do not have any effect on the target variable some\n",
    "#df_distinct.drop(columns=['Okul Türü', 'Okul Türü_y', 'Okul Türü_x', 'name', 'cd_value', 'İlçeler', 'Kayıtlı Nüfus'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3376ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2f0a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining categorical and numerical features\n",
    "categorical_features = ['obj_type','info', 'notation','or_src_id', 'Province','Municipio',]\n",
    "numeric_features = ['population','income','total_sales', 'second_sales', 'water_access', 'elec_cons', 'building_perm',\n",
    "           'land_permited', 'labour_fource','unemployment','agricultural', 'life_time', 'hb_per100000', 'fertility',\n",
    "           'hh_size','latitude','longitude', 'nearest_fault_distance_km','nearest_eq_distance_km',\n",
    "           'Longitude','Latitude', 'eclass_public','eclass_private','eclass_total','enumber_public','enumber_private',\n",
    "           'enumber_total', 'e_male_public', 'e_female_public', 'e_total_public', 'e_male_private', 'e_female_private',\n",
    "           'e_total_private','e_total','et_male_public','et_female_public', 'et_total_public','et_male_private', \n",
    "           'et_total_private', 'et_total', 'hclass_public','hclass_private','hclass_total','hnumber_public',\n",
    "           'hnumber_private', 'hnumber_total','h_male_public','h_female_public','h_total_public','h_male_private',\n",
    "           'h_female_private','h_total_private','h_total','hs_religious_male_public','hs_religious_female_public',\n",
    "           'hs_religious_total_public', 'hs_religious_male_private', 'hs_religious_female_private', 'hs_religious_total_private',\n",
    "           'hs_religious_total','h_male_occupational_public','h_female_occupational_public','h_total_occupational_public',\n",
    "           'h_male_occupational_private','h_male_occupational_private_1','h_total_ocupational_private','h_occupational_total',\n",
    "           'h_male_normal_public','h_female_normal_public','h_total_normal_public','h_male_normal_private','h_female_normal_private',\n",
    "           'h_total_normal_private','h_normal_total','ht_male_public','ht_female_public','ht_total_public','ht_male_private',\n",
    "           'ht_female_private','ht_total_private','ht_toplam','mclass_public','mclass_private','mclass_total','mnumber_public',\n",
    "           'mnumber_private','mnumber_total','m_male_public','m_female_public','m_total_public','m_male_private','m_female_private',\n",
    "           'm_total_private','m_total','mt_male_public','mt_female_public','mt_total_public','mt_male_private','mt_female_private',\n",
    "           'mt_total_private','mt_total','pclass_public','pclass_private','pclass_toplam','pnumber_public','pnumber_private',\n",
    "           'pnumber_total','p_male_public','p_female_public','p_total_public','p_male_private','p_female_private','p_total_private',\n",
    "           \"p_total\",'pt_male_public','pt_female_public','pt_total_public','pt_male_private','pt_female_private','pt_total_private',\n",
    "           'pt_total',\n",
    "           ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3f5d2776",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_distinct.dropna(inplace=True)            \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1b4f5fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "setup() got an unexpected keyword argument 'transformed_feature_names'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpycaret\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclassification\u001b[39;00m \u001b[39mimport\u001b[39;00m setup, create_model\n\u001b[0;32m----> 4\u001b[0m selection \u001b[39m=\u001b[39m setup(data\u001b[39m=\u001b[39;49mdf_distinct, \n\u001b[1;32m      5\u001b[0m                   target\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mdamage_gra\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m                   train_size\u001b[39m=\u001b[39;49m\u001b[39m0.7\u001b[39;49m, \n\u001b[1;32m      7\u001b[0m                   normalize\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, \n\u001b[1;32m      8\u001b[0m                   transformation\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      9\u001b[0m                   session_id\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m,  \u001b[39m# for reproducibility\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m                   fold_shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m , \u001b[39m# activate shuffling,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m                   transformed_feature_names\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mget_feature_names_out\u001b[39;49m\u001b[39m'\u001b[39;49m\n\u001b[1;32m     12\u001b[0m                  )\n\u001b[1;32m     15\u001b[0m \u001b[39m# Create Ridge Regression model\u001b[39;00m\n\u001b[1;32m     16\u001b[0m ridge_model \u001b[39m=\u001b[39m create_model(\u001b[39m'\u001b[39m\u001b[39mridge\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: setup() got an unexpected keyword argument 'transformed_feature_names'"
     ]
    }
   ],
   "source": [
    "from pycaret.classification import setup, create_model\n",
    "\n",
    "\n",
    "selection = setup(data=df_distinct, \n",
    "                  target='damage_gra',\n",
    "                  train_size=0.7, \n",
    "                  normalize=True, \n",
    "                  transformation=True,\n",
    "                  session_id=123,  # for reproducibility\n",
    "                  fold_shuffle=True , # activate shuffling,\n",
    "                  transformed_feature_names='get_feature_names_out'\n",
    "                 )\n",
    "\n",
    "\n",
    "# Create Ridge Regression model\n",
    "ridge_model = create_model('ridge')\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = ridge_model.coef_\n",
    "\n",
    "# Get column names\n",
    "column_names = df_distinct.columns\n",
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "feature_importance_df = pd.DataFrame({'Variable': column_names, 'Importance': feature_importance})\n",
    "\n",
    "# Sort by importance (absolute values)\n",
    "feature_importance_df['Importance_abs'] = abs(feature_importance_df['Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance_abs', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the selected variables\n",
    "print(\"Selected Variables:\")\n",
    "print(feature_importance_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5b4b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Ridge Regression model\n",
    "ridge_model = create_model('ridge')\n",
    "lasso_model = create_model('lasso')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cd494",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get feature importance\n",
    "feature_importance = ridge_model.coef_\n",
    "\n",
    "# Get column names\n",
    "column_names = df_distinct.columns\n",
    "\n",
    "print(len(column_names))\n",
    "print(len(feature_importance))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36ba033",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a DataFrame to display feature importance\n",
    "feature_importance_df = pd.DataFrame({'Variable': column_names, 'Importance': feature_importance})\n",
    "\n",
    "# Sort by importance (absolute values)\n",
    "feature_importance_df['Importance_abs'] = abs(feature_importance_df['Importance'])\n",
    "feature_importance_df = feature_importance_df.sort_values('Importance_abs', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Print the selected variables\n",
    "print(\"Selected Variables:\")\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e515d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the PyCaret environment with preprocessing\n",
    "s = ClassificationExperiment()\n",
    "s = setup(df_distinct, target='damage_gra', session_id=42, preprocess=True, normalize=True, train_size=0.8,)\n",
    "s.eda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d9305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0bdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "best_model = s.compare_models()\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd54c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cc5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(best, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51466ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(best, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d55a7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the best model\n",
    "trained_model = finalize_model(best_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d48033d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the train and test datasets\n",
    "X_train = get_config('X_train')\n",
    "X_test = get_config('X_test')\n",
    "y_train = get_config('y_train')\n",
    "y_test = get_config('y_test')\n",
    "\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d61e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "# Make predictions on new data\n",
    "predictions = predict_model(trained_model, data= X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e5d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already trained and finalized a model\n",
    "trained_model = load_model('path_to_trained_model')\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_model(trained_model, plot='confusion_matrix')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d79060",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12040d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db.info(),)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7389031e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the GeoDataFrame to a DataFrame\n",
    "df = pd.DataFrame(db)\n",
    "\n",
    "# The 'geometry' column is automatically converted to a string representation of the geometry object,\n",
    "# so you may want to convert it back to a GeoSeries using geopandas' 'from_wkt()' function:\n",
    "from shapely.wkt import loads\n",
    "df['geometry'] = df['geometry'].apply(lambda x: loads(x.wkt))\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc417dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf1 = setup(data = df, target = 'damage_gra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c7e917",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = setup (data = df, target = 'damage_gra', categorical_features = category, numeric_features = numerical)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newpycaret",
   "language": "python",
   "name": "newpycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
